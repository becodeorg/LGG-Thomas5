{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRYGR0wcJ8Qb"
   },
   "source": [
    "# Image Recognizer -> CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgxRRMkSyDNx",
    "outputId": "5386686f-fd8f-4810-aa51-1ac59a7153e8"
   },
   "outputs": [],
   "source": [
    "!pip install wget # Install the wget package for file download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIYKH8sMJyV5",
    "outputId": "8a36e891-277f-4eed-c406-c8cf8c1e32f7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "import os\n",
    "import wget\n",
    "import random\n",
    "import shutil\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VbilWiUKGm9",
    "outputId": "a12a63bf-ede1-442c-9521-a4cfa655f66a"
   },
   "outputs": [],
   "source": [
    "# Download the Bike zip file\n",
    "bike_zip_path = tf.keras.utils.get_file(\n",
    "    \"Bike.zip\",\n",
    "    \"https://github.com/Rhodham96/LGG-Thomas5/raw/main/PersonalProjects/CNN/Bike.zip\", # Use 'raw' instead of 'blob' for direct download\n",
    "    extract=False\n",
    ")\n",
    "\n",
    "# Extract the Bike zip file\n",
    "with zipfile.ZipFile(bike_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/datasets/Train')\n",
    "\n",
    "bike_data_dir = pathlib.Path('/content/datasets/Train/Bike')\n",
    "print(bike_data_dir)\n",
    "print(os.path.abspath(bike_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLprdVuEnnG5",
    "outputId": "e9347928-d0d4-47e9-bcc2-b89ce665dcb1"
   },
   "outputs": [],
   "source": [
    "# Download the Car zip file\n",
    "car_zip_path = '/content/datasets/Car.zip'\n",
    "url = \"https://github.com/Rhodham96/LGG-Thomas5/raw/main/PersonalProjects/CNN/Car.zip\"\n",
    "wget.download(url, car_zip_path) # Download and save to desired location\n",
    "\n",
    "# Extract the Car zip file\n",
    "import zipfile # Import zipfile for file extraction\n",
    "with zipfile.ZipFile(car_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/datasets/Train')\n",
    "\n",
    "car_data_dir = pathlib.Path('/content/datasets/Train/Car')\n",
    "print(car_data_dir)\n",
    "print(os.path.abspath(car_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxEWHZGLoljt",
    "outputId": "d4384b64-4954-4ce6-9c40-a2f454fb5e21"
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"/content/datasets/Train\")\n",
    "image_count = len(list(data_dir.glob('*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQYw7-ykrDAK",
    "outputId": "c96e13fd-15f7-44cc-d4d2-a6ba99ec2d69"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Define the source and target directories\n",
    "source_dir = '/content/datasets/Train/Bike'\n",
    "target_dir = '/content/datasets/Val/Bike'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get all files in the source directory\n",
    "all_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "# Randomly select 400 files from the list\n",
    "selected_files = random.sample(all_files, 435)\n",
    "\n",
    "# Move the selected files to the target directory\n",
    "for file in selected_files:\n",
    "    src_file = os.path.join(source_dir, file)\n",
    "    tgt_file = os.path.join(target_dir, file)\n",
    "\n",
    "    # Move the file\n",
    "    shutil.move(src_file, tgt_file)\n",
    "\n",
    "print(f\"Moved {len(selected_files)} files from {source_dir} to {target_dir}\")\n",
    "\n",
    "# Define the source and target directories\n",
    "source_dir = '/content/datasets/Train/Car'\n",
    "target_dir = '/content/datasets/Val/Car'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get all files in the source directory\n",
    "all_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "# Randomly select 400 files from the list\n",
    "selected_files = random.sample(all_files, 435)\n",
    "\n",
    "# Move the selected files to the target directory\n",
    "for file in selected_files:\n",
    "    src_file = os.path.join(source_dir, file)\n",
    "    tgt_file = os.path.join(target_dir, file)\n",
    "\n",
    "    # Move the file\n",
    "    shutil.move(src_file, tgt_file)\n",
    "\n",
    "print(f\"Moved {len(selected_files)} files from {source_dir} to {target_dir}\")\n",
    "\n",
    "CarVal = '/content/datasets/dataset/CarVal'\n",
    "BikeVal = '/content/datasets/dataset/BikeVal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_04StcVRrXnr",
    "outputId": "c95eb01d-56e3-4bfa-e832-d123d9ef4687"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Define the source and target directories\n",
    "source_dir = '/content/datasets/Train/Bike'\n",
    "target_dir = '/content/datasets/Test/Bike'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get all files in the source directory\n",
    "all_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "# Randomly select 400 files from the list\n",
    "selected_files = random.sample(all_files, 10)\n",
    "\n",
    "# Move the selected files to the target directory\n",
    "for file in selected_files:\n",
    "    src_file = os.path.join(source_dir, file)\n",
    "    tgt_file = os.path.join(target_dir, file)\n",
    "\n",
    "    # Move the file\n",
    "    shutil.move(src_file, tgt_file)\n",
    "\n",
    "print(f\"Moved {len(selected_files)} files from {source_dir} to {target_dir}\")\n",
    "\n",
    "# Define the source and target directories\n",
    "source_dir = '/content/datasets/Train/Car'\n",
    "target_dir = '/content/datasets/Test/Car'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get all files in the source directory\n",
    "all_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "# Randomly select 400 files from the list\n",
    "selected_files = random.sample(all_files, 10)\n",
    "\n",
    "# Move the selected files to the target directory\n",
    "for file in selected_files:\n",
    "    src_file = os.path.join(source_dir, file)\n",
    "    tgt_file = os.path.join(target_dir, file)\n",
    "\n",
    "    # Move the file\n",
    "    shutil.move(src_file, tgt_file)\n",
    "\n",
    "print(f\"Moved {len(selected_files)} files from {source_dir} to {target_dir}\")\n",
    "\n",
    "Test = '/content/datasets/dataset/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozj7Rbmsrvzm"
   },
   "outputs": [],
   "source": [
    "Train_dir = pathlib.Path(\"/content/datasets/Train\")\n",
    "BikeTrain_dir = pathlib.Path(\"/content/datasets/Train/Bike\")\n",
    "CarTrain_dir = pathlib.Path(\"/content/datasets/Train/Car\")\n",
    "\n",
    "Val_dir = pathlib.Path(\"/content/datasets/Val\")\n",
    "BikeVal_dir = pathlib.Path(\"/content/datasets/Val/Bike\")\n",
    "CarVal_dir = pathlib.Path(\"/content/datasets/Val/Car\")\n",
    "\n",
    "Test_dir = pathlib.Path(\"/content/datasets/Test\")\n",
    "BikeTest_dir = pathlib.Path(\"/content/datasets/Test/Bike\")\n",
    "CarTest_dir = pathlib.Path(\"/content/datasets/Test/Car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9htSKFYPuyph",
    "outputId": "721e2130-e799-492d-c2b5-7a3870b78c91"
   },
   "outputs": [],
   "source": [
    "def remove_macosx(root_dir):\n",
    "    \"\"\"\n",
    "    Removes all directories named '__MACOSX' and their contents\n",
    "    within the specified root directory.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == '__MACOSX':\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                print(f\"Removing: {dir_path}\")\n",
    "                shutil.rmtree(dir_path)\n",
    "\n",
    "# Call the function to remove '__MACOSX' directories within 'content'\n",
    "content_dir = '/content' # Replace with the actual path to your 'content' directory\n",
    "remove_macosx(content_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze6rPH97zvdg",
    "outputId": "84ad5ea6-307a-4bb1-8aab-be7da60f2da3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imghdr\n",
    "import shutil  # Import shutil for file operations\n",
    "\n",
    "def find_unsupported_images(directory):\n",
    "    unsupported_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                image_type = imghdr.what(file_path)\n",
    "                if image_type not in ['jpeg', 'png', 'gif', 'bmp']:\n",
    "                    unsupported_files.append(file_path)\n",
    "            except Exception:  # Handle potential errors during image type detection\n",
    "                unsupported_files.append(file_path)\n",
    "    return unsupported_files\n",
    "\n",
    "def remove_unsupported_images(unsupported_files):\n",
    "    for file_path in unsupported_files:\n",
    "        print(f\"Removing unsupported file: {file_path}\")\n",
    "        os.remove(file_path)  # Remove the unsupported file\n",
    "\n",
    "# ... (Your existing code for loading data) ...\n",
    "\n",
    "# Find and remove unsupported images before creating the datasets\n",
    "unsupported_train_images = find_unsupported_images(Train_dir)\n",
    "unsupported_val_images = find_unsupported_images(Val_dir)\n",
    "\n",
    "remove_unsupported_images(unsupported_train_images)\n",
    "remove_unsupported_images(unsupported_val_images)\n",
    "\n",
    "print(\"Unsupported images in training directory:\", unsupported_train_images)\n",
    "print(\"Unsupported images in validation directory:\", unsupported_val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NN9B-iF1Hfc",
    "outputId": "8a29cdbd-3f87-4ede-d0bd-dc3ede9e3730"
   },
   "outputs": [],
   "source": [
    "img_height = 200  # Set your desired image height\n",
    "img_width = 200  # Set your desired image width\n",
    "batch_size = 32  # Set your desired batch size\n",
    "\n",
    "# Load the training dataset, specifying supported image types\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    Train_dir,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    interpolation='nearest',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Load the validation dataset, specifying supported image types\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    Val_dir,\n",
    "    seed=42,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',  # Change to 'categorical' to match train_data\n",
    "    image_size=(img_height, img_width),\n",
    "    interpolation='nearest',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    Test_dir,\n",
    "    seed=42,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',  # Change to 'categorical' to match train_data\n",
    "    image_size=(img_height, img_width),\n",
    "    interpolation='nearest',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "UmZCVEhWowvt",
    "outputId": "43e6aec8-4030-4757-eed1-0633f17ddd7b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "class_names = train_data.class_names\n",
    "for images, labels in train_data.take(1):\n",
    "  for i in range(3):\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "    # Get the index of the predicted class\n",
    "    predicted_class_index = np.argmax(labels[i].numpy())\n",
    "\n",
    "    plt.title(class_names[predicted_class_index]) # Index with the integer\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "IpXJCjxNo0JO",
    "outputId": "48d86376-7397-4535-c7a7-1c4921ed06fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(128,4, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64,4, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,4, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16,4, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),  # Use CategoricalCrossentropy\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "  train_data,\n",
    "  validation_data=val_data,\n",
    "  epochs=10,\n",
    "  callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vv0RKCXKAUw1",
    "outputId": "a4ec6d30-a8bb-40e8-f814-c269c2f5d165"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch of test data\n",
    "for images, labels in test_data.take(1):\n",
    "  random_indices = random.sample(range(len(images)), 5)\n",
    "  for i in random_indices:  # Test with 5 images\n",
    "    # Get the image and its true label\n",
    "    image = images[i].numpy().astype(\"uint8\")\n",
    "    true_label = np.argmax(labels[i].numpy())\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(tf.expand_dims(images[i], 0))\n",
    "    predicted_label = np.argmax(prediction[0])\n",
    "\n",
    "    # Display the image and prediction\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {class_names[true_label]}, Predicted: {class_names[predicted_label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTjApWHs7Yxo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
